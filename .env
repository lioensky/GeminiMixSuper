# R1模型代理输入端口, 若未设置则默认使用DeepSeek官方API
PROXY_URL=

# 正式输出模型代理输入端口
PROXY_URL2=

# 图像识别模型输入端口
PROXY_URL3=

# 联网模型输入端口
PROXY_URL4=

# 代理服务器输出端口
PROXY_PORT=4120

# Deepseek R1 模型配置
DEEPSEEK_R1_API_KEY=
# 若未设置, 默认使用DeepSeek官方R1模型, 若使用siliconflow的DeepSeek R1需手动开启, 建议使用Pro版
DEEPSEEK_R1_MODEL=
DEEPSEEK_R1_MAX_TOKENS=7985
DEEPSEEK_R1_CONTEXT_WINDOW=64000
DEEPSEEK_R1_TEMPERATURE=0.7

#考虑到R1模型卡顿，可参考如下模型列表：
## deepseek-ai/DeepSeek-R1-Distill-Llama-70B
## deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
## deepseek-ai/DeepSeek-R1-Distill-Qwen-14B

# 正式输出模型配置
Model_output_API_KEY=
Model_output_MODEL=gemini-2.0-pro-exp
Model_output_MAX_TOKENS=65536
Model_output_CONTEXT_WINDOW=1048576
Model_output_TEMPERATURE=0.7
Model_output_WebSearch=False

# 图像识别模型 模型配置(暂定为gemini-2.0-pro-exp)
Image_Model_API_KEY=
Image_MODEL=gemini-2.0-pro-exp
Image_Model_MAX_TOKENS=7985
Image_Model_CONTEXT_WINDOW=32000
Image_Model_TEMPERATURE=0.4

# 联网主动判断模型 模型配置(gemini-2.0-flash-lite-preview更快但不够稳定,若出现联网判断输出不为yes或no,那么使用gemini-2.0-flash-thinking-exp)
# 用于快速判断是否需要联网, 仅控制其输出yes/no, 但lite小模型其仅在英文提问时效果较好
SearchDetermine_API_KEY=
# SearchDetermine_MODEL=gemini-2.0-flash-lite-preview-02-05
SearchDetermine_MODEL=gemini-2.0-flash-exp
SearchDetermine_Model_MAX_TOKENS=7985
SearchDetermine_Model_CONTEXT_WINDOW=32000
SearchDetermine_Model_TEMPERATURE=0.4


# 联网搜索模型 模型配置(暂定为gemini-2.0-pro-exp)
GoogleSearch_API_KEY=
GoogleSearch_MODEL=gemini-2.0-pro-exp
GoogleSearch_Model_MAX_TOKENS=7985
GoogleSearch_Model_CONTEXT_WINDOW=32000
GoogleSearch_Model_TEMPERATURE=0.4

# 最终混合模型名称
HYBRID_MODEL_NAME=GeminiMIXR1

# 输出 API 密钥
OUTPUT_API_KEY=

# URL解析核心配置
PROXY_URL_PARSE=http://127.0.0.1:7890
REQUEST_TIMEOUT=30000
REQUEST_MAX_REDIRECTS=5

# 请求头配置
REQUEST_HEADERS_USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36
REQUEST_HEADERS_ACCEPT=text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
REQUEST_HEADERS_ACCEPT_LANGUAGE=zh-CN,zh;q=0.9,en;q=0.8

# 代理重试配置
PROXY_RETRY_ATTEMPTS=3
PROXY_RETRY_DELAY=2000
